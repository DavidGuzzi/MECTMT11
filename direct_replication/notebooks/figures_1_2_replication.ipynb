{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Smets & Wouters (2007) - Replicacion de Figuras 1 y 2\n",
    "\n",
    "Este notebook replica las Figuras 1 y 2 del paper \"Shocks and Frictions in US Business Cycles: A Bayesian DSGE Approach\" (AER, 2007).\n",
    "\n",
    "**Figura 1**: Forecast Error Variance Decomposition (FEVD)\n",
    "- Descomposicion de varianza del error de pronostico para GDP growth, Inflation y Interest rate\n",
    "- Muestra la contribucion de cada shock estructural a diferentes horizontes\n",
    "\n",
    "**Figura 2**: Impulse Response Functions (IRFs) a shocks de demanda\n",
    "- Respuestas de Output y Hours worked a shocks de demanda\n",
    "- Shocks: Risk premium (eb), Government spending (eg), Investment-specific (eqs)\n",
    "\n",
    "**Requisitos previos:**\n",
    "- GNU Octave instalado y en PATH\n",
    "- Dynare instalado\n",
    "- Archivo `usmodel_mode.mat` con posterior mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "\n",
    "from direct_replication import DynareInterface\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports completados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar rutas - MODIFICAR SEGUN TU INSTALACION\n",
    "\n",
    "# Configurar ruta de Octave (necesario en Windows)\n",
    "os.environ['OCTAVE_EXECUTABLE'] = r'C:\\Program Files\\GNU Octave\\Octave-10.3.0\\mingw64\\bin\\octave-cli.exe'\n",
    "\n",
    "DYNARE_PATH = r'C:\\dynare\\6.5\\matlab'  # Ruta a carpeta matlab de Dynare\n",
    "REPO_PATH = Path.cwd().parent.parent / 'repo'  # Carpeta con datos (.xls)\n",
    "MODEL_PATH = Path.cwd().parent / 'model'  # Carpeta con .mod files\n",
    "\n",
    "print(f\"Octave executable: {os.environ['OCTAVE_EXECUTABLE']}\")\n",
    "print(f\"Dynare path: {DYNARE_PATH}\")\n",
    "print(f\"Repo path: {REPO_PATH}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Repo exists: {REPO_PATH.exists()}\")\n",
    "print(f\"Model exists: {MODEL_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Test de Conexion Octave + Dynare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oct2py import Oct2Py\n",
    "\n",
    "# Test basico\n",
    "try:\n",
    "    oc = Oct2Py()\n",
    "    result = oc.eval('2 + 2', nout=1)\n",
    "    print(f\"Octave conectado: 2 + 2 = {result}\")\n",
    "    \n",
    "    # Test Dynare\n",
    "    oc.addpath(DYNARE_PATH)\n",
    "    dynare_exists = oc.eval('exist(\"dynare\")', nout=1)\n",
    "    if dynare_exists == 2:\n",
    "        print(\"Dynare encontrado\")\n",
    "    else:\n",
    "        print(\"Dynare NO encontrado - verificar DYNARE_PATH\")\n",
    "    \n",
    "    oc.exit()\n",
    "    print(\"\\nTodo listo!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Ver setup_instructions.md para solucion de problemas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Datos de Referencia del Paper\n",
    "\n",
    "### Figura 1: Forecast Error Variance Decomposition (FEVD)\n",
    "Muestra como los 7 shocks estructurales contribuyen a la varianza del error de pronostico en diferentes horizontes para:\n",
    "- GDP Growth (dy)\n",
    "- Inflation (pinfobs)\n",
    "- Interest Rate (robs)\n",
    "\n",
    "### Figura 2: IRFs a Shocks de Demanda\n",
    "Muestra las respuestas de Output (y) y Hours (lab) a los 3 shocks de \"demanda\":\n",
    "- Risk premium shock (eb)\n",
    "- Government spending shock (eg)\n",
    "- Investment-specific shock (eqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiciones para las figuras\n",
    "\n",
    "# Labels para los 7 shocks estructurales\n",
    "SHOCK_LABELS = {\n",
    "    'ea': 'Productivity',\n",
    "    'eb': 'Risk premium',\n",
    "    'eg': 'Exog. spending',\n",
    "    'eqs': 'Investment',\n",
    "    'em': 'Monetary',\n",
    "    'epinf': 'Price markup',\n",
    "    'ew': 'Wage markup'\n",
    "}\n",
    "\n",
    "SHOCK_ORDER = ['ea', 'eb', 'eg', 'eqs', 'em', 'epinf', 'ew']\n",
    "\n",
    "# Figura 1: Variables para FEVD\n",
    "FIGURE1_VARIABLES = ['dy', 'pinfobs', 'robs']\n",
    "FIGURE1_LABELS = {\n",
    "    'dy': 'GDP Growth',\n",
    "    'pinfobs': 'Inflation',\n",
    "    'robs': 'Federal Funds Rate'\n",
    "}\n",
    "\n",
    "# Figura 2: Variables y shocks de demanda\n",
    "DEMAND_SHOCKS = ['eb', 'eg', 'eqs']\n",
    "FIGURE2_VARIABLES = ['y', 'lab']\n",
    "FIGURE2_LABELS = {\n",
    "    'y': 'Output',\n",
    "    'lab': 'Hours'\n",
    "}\n",
    "\n",
    "print(\"Configuracion de figuras definida\")\n",
    "print(f\"\\nFigura 1 - FEVD para: {FIGURE1_VARIABLES}\")\n",
    "print(f\"Figura 2 - IRFs de {FIGURE2_VARIABLES} a shocks: {DEMAND_SHOCKS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Ejecutar Dynare con Modelo Modificado\n",
    "\n",
    "Usamos `usmodel_figures.mod` que tiene el comando `stoch_simul` modificado para generar:\n",
    "- Conditional Variance Decomposition (FEVD) para horizontes 1-40\n",
    "- IRFs para variables adicionales (y, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar interfaz Dynare\n",
    "di = DynareInterface(DYNARE_PATH, str(MODEL_PATH))\n",
    "\n",
    "print(\"Interfaz Dynare inicializada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar modelo modificado para figuras\n",
    "# Este modelo incluye conditional_variance_decomposition y variables adicionales\n",
    "\n",
    "print(\"Ejecutando usmodel_figures.mod...\")\n",
    "print(\"(Esto puede tardar varios minutos)\\n\")\n",
    "\n",
    "di.run_model('usmodel_figures.mod')\n",
    "\n",
    "print(\"\\nDynare completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Extraer FEVD para Figura 1\n",
    "\n",
    "La Conditional Variance Decomposition muestra como cada shock contribuye a la varianza del error de pronostico en diferentes horizontes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fevd(di, max_horizon=40):\n",
    "    \"\"\"\n",
    "    Extrae la Conditional Variance Decomposition de Dynare.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con columnas: horizon, variable, shock, variance_share\n",
    "    \"\"\"\n",
    "    # Verificar que existe\n",
    "    has_fevd = di.oc.eval('isfield(oo_, \"conditional_variance_decomposition\")', nout=1)\n",
    "    if not has_fevd:\n",
    "        raise RuntimeError(\"FEVD no encontrada. Verificar stoch_simul con conditional_variance_decomposition.\")\n",
    "    \n",
    "    # Obtener dimensiones del array\n",
    "    fevd_size = di.oc.eval('size(oo_.conditional_variance_decomposition)', nout=1)\n",
    "    n_horizons = int(fevd_size[0])\n",
    "    n_vars = int(fevd_size[1])\n",
    "    n_shocks = int(fevd_size[2])\n",
    "    \n",
    "    print(f\"FEVD dimensions: {n_horizons} horizons x {n_vars} variables x {n_shocks} shocks\")\n",
    "    \n",
    "    # Obtener nombres de variables endogenas\n",
    "    n_endo = int(di.oc.eval('M_.endo_nbr', nout=1))\n",
    "    var_names = []\n",
    "    for i in range(n_endo):\n",
    "        name = di.oc.eval(f'deblank(M_.endo_names{{{i+1}}})', nout=1)\n",
    "        var_names.append(str(name).strip())\n",
    "    \n",
    "    # Obtener nombres de shocks\n",
    "    n_exo = int(di.oc.eval('M_.exo_nbr', nout=1))\n",
    "    shock_names = []\n",
    "    for i in range(n_exo):\n",
    "        name = di.oc.eval(f'deblank(M_.exo_names{{{i+1}}})', nout=1)\n",
    "        shock_names.append(str(name).strip())\n",
    "    \n",
    "    print(f\"Variables: {var_names[:10]}...\")\n",
    "    print(f\"Shocks: {shock_names}\")\n",
    "    \n",
    "    # Extraer array FEVD\n",
    "    fevd_array = di.oc.eval('oo_.conditional_variance_decomposition', nout=1)\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    data = []\n",
    "    for h in range(min(n_horizons, max_horizon)):\n",
    "        for v in range(n_vars):\n",
    "            for s in range(n_shocks):\n",
    "                # FEVD esta en porcentaje (0-100)\n",
    "                value = fevd_array[h, v, s]\n",
    "                data.append({\n",
    "                    'horizon': h + 1,\n",
    "                    'variable': var_names[v],\n",
    "                    'shock': shock_names[s],\n",
    "                    'variance_share': float(value)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Extraer FEVD\n",
    "print(\"Extrayendo FEVD...\\n\")\n",
    "fevd_df = extract_fevd(di, max_horizon=40)\n",
    "\n",
    "print(f\"\\nFEVD extraida: {len(fevd_df)} filas\")\n",
    "fevd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que FEVD suma 100% para cada (variable, horizonte)\n",
    "print(\"Verificando que FEVD suma 100% para cada variable y horizonte...\\n\")\n",
    "\n",
    "for var in FIGURE1_VARIABLES:\n",
    "    var_data = fevd_df[fevd_df['variable'] == var]\n",
    "    for h in [1, 4, 8, 20, 40]:\n",
    "        h_data = var_data[var_data['horizon'] == h]\n",
    "        total = h_data['variance_share'].sum()\n",
    "        status = \"OK\" if abs(total - 100) < 0.5 else \"WARNING\"\n",
    "        print(f\"  {var} h={h}: {total:.2f}% [{status}]\")\n",
    "\n",
    "print(\"\\nVerificacion completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Extraer IRFs para Figura 2\n",
    "\n",
    "Extraemos las IRFs de Output (y) y Hours (lab) a los shocks de demanda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer IRFs\n",
    "print(\"Extrayendo IRFs...\\n\")\n",
    "\n",
    "irfs_df = di.get_irfs(periods=20)\n",
    "\n",
    "print(f\"IRFs extraidas: {len(irfs_df)} observaciones\")\n",
    "print(f\"\\nVariables disponibles: {irfs_df['variable'].unique()}\")\n",
    "print(f\"Shocks disponibles: {irfs_df['shock'].unique()}\")\n",
    "\n",
    "irfs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar IRFs para Figura 2\n",
    "figure2_irfs = irfs_df[\n",
    "    (irfs_df['variable'].isin(FIGURE2_VARIABLES)) & \n",
    "    (irfs_df['shock'].isin(DEMAND_SHOCKS))\n",
    "].copy()\n",
    "\n",
    "print(f\"IRFs para Figura 2: {len(figure2_irfs)} observaciones\")\n",
    "print(f\"\\nVariables: {figure2_irfs['variable'].unique()}\")\n",
    "print(f\"Shocks: {figure2_irfs['shock'].unique()}\")\n",
    "\n",
    "figure2_irfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. Graficar Figura 1: FEVD\n",
    "\n",
    "Creamos un grafico de areas apiladas (stacked area chart) para cada variable, mostrando la contribucion de cada shock a la varianza del error de pronostico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure1_fevd(fevd_df, variables, shock_order, shock_labels, var_labels, max_horizon=40):\n",
    "    \"\"\"\n",
    "    Grafica Figura 1: FEVD como stacked area charts.\n",
    "    \n",
    "    Estilo del paper:\n",
    "    - 3 paneles (GDP growth, Inflation, Interest rate)\n",
    "    - Eje X: Horizonte (quarters)\n",
    "    - Eje Y: Porcentaje de varianza (0-100%)\n",
    "    - Areas apiladas para cada shock\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Colores para los shocks\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(shock_order)))\n",
    "    \n",
    "    for idx, var in enumerate(variables):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Filtrar para esta variable\n",
    "        var_data = fevd_df[(fevd_df['variable'] == var) & (fevd_df['horizon'] <= max_horizon)].copy()\n",
    "        \n",
    "        # Pivot a formato wide\n",
    "        pivot_data = var_data.pivot(\n",
    "            index='horizon', \n",
    "            columns='shock', \n",
    "            values='variance_share'\n",
    "        )\n",
    "        \n",
    "        # Reordenar columnas segun shock_order\n",
    "        available_shocks = [s for s in shock_order if s in pivot_data.columns]\n",
    "        pivot_data = pivot_data[available_shocks]\n",
    "        \n",
    "        # Grafico de area apilada\n",
    "        pivot_data.plot.area(\n",
    "            ax=ax,\n",
    "            stacked=True,\n",
    "            alpha=0.85,\n",
    "            color=colors[:len(available_shocks)],\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        ax.set_title(var_labels.get(var, var), fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Horizon (quarters)', fontsize=10)\n",
    "        ax.set_ylabel('Percent', fontsize=10)\n",
    "        ax.set_xlim(1, max_horizon)\n",
    "        ax.set_ylim(0, 100)\n",
    "        \n",
    "        # Leyenda solo en el ultimo panel\n",
    "        if idx == len(variables) - 1:\n",
    "            ax.legend(\n",
    "                [shock_labels.get(s, s) for s in available_shocks],\n",
    "                loc='center left',\n",
    "                bbox_to_anchor=(1.02, 0.5),\n",
    "                fontsize=9\n",
    "            )\n",
    "        else:\n",
    "            ax.legend().remove()\n",
    "        \n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.suptitle('Figure 1: Forecast Error Variance Decomposition', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Graficar Figura 1\n",
    "print(\"Generando Figura 1: FEVD...\\n\")\n",
    "\n",
    "fig1 = plot_figure1_fevd(\n",
    "    fevd_df, \n",
    "    FIGURE1_VARIABLES, \n",
    "    SHOCK_ORDER, \n",
    "    SHOCK_LABELS, \n",
    "    FIGURE1_LABELS,\n",
    "    max_horizon=40\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "print(\"\\nFigura 1 generada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 7. Graficar Figura 2: IRFs a Shocks de Demanda\n",
    "\n",
    "Creamos un grid 2x3 mostrando las respuestas de Output y Hours a los 3 shocks de demanda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure2_irfs(irfs_df, variables, shocks, shock_labels, var_labels):\n",
    "    \"\"\"\n",
    "    Grafica Figura 2: IRFs a shocks de demanda.\n",
    "    \n",
    "    Estilo del paper:\n",
    "    - 2 filas (Output, Hours)\n",
    "    - 3 columnas (Risk premium, Government, Investment)\n",
    "    - Line plots con referencia en y=0\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    \n",
    "    for i, var in enumerate(variables):\n",
    "        for j, shock in enumerate(shocks):\n",
    "            ax = axes[i, j]\n",
    "            \n",
    "            # Filtrar datos\n",
    "            irf_data = irfs_df[\n",
    "                (irfs_df['variable'] == var) & \n",
    "                (irfs_df['shock'] == shock)\n",
    "            ].sort_values('period')\n",
    "            \n",
    "            if len(irf_data) > 0:\n",
    "                # Grafico de linea\n",
    "                ax.plot(irf_data['period'], irf_data['value'], 'b-', linewidth=2)\n",
    "                ax.fill_between(irf_data['period'], 0, irf_data['value'], alpha=0.2)\n",
    "            \n",
    "            # Linea de referencia en y=0\n",
    "            ax.axhline(0, color='k', linestyle='--', linewidth=0.8)\n",
    "            \n",
    "            # Titulos\n",
    "            if i == 0:\n",
    "                ax.set_title(shock_labels.get(shock, shock), fontsize=11, fontweight='bold')\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(var_labels.get(var, var), fontsize=11, fontweight='bold')\n",
    "            if i == 1:\n",
    "                ax.set_xlabel('Quarters', fontsize=10)\n",
    "            \n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_xlim(0, 20)\n",
    "    \n",
    "    plt.suptitle('Figure 2: Estimated Mean Impulse Responses to Demand Shocks', \n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Graficar Figura 2\n",
    "print(\"Generando Figura 2: IRFs a shocks de demanda...\\n\")\n",
    "\n",
    "fig2 = plot_figure2_irfs(\n",
    "    figure2_irfs,\n",
    "    FIGURE2_VARIABLES,\n",
    "    DEMAND_SHOCKS,\n",
    "    SHOCK_LABELS,\n",
    "    FIGURE2_LABELS\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "print(\"\\nFigura 2 generada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 8. Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar figuras\n",
    "output_dir = Path.cwd()\n",
    "\n",
    "fig1.savefig(output_dir / 'figure1_fevd.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Figura 1 guardada en: {output_dir / 'figure1_fevd.png'}\")\n",
    "\n",
    "fig2.savefig(output_dir / 'figure2_irfs.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Figura 2 guardada en: {output_dir / 'figure2_irfs.png'}\")\n",
    "\n",
    "# Guardar datos en CSV\n",
    "fevd_figure1 = fevd_df[fevd_df['variable'].isin(FIGURE1_VARIABLES)]\n",
    "fevd_figure1.to_csv(output_dir / 'figure1_fevd_data.csv', index=False)\n",
    "print(f\"\\nDatos FEVD guardados en: {output_dir / 'figure1_fevd_data.csv'}\")\n",
    "\n",
    "figure2_irfs.to_csv(output_dir / 'figure2_irfs_data.csv', index=False)\n",
    "print(f\"Datos IRFs guardados en: {output_dir / 'figure2_irfs_data.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 9. Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen FEVD en horizontes clave\n",
    "print(\"=\"*70)\n",
    "print(\"RESUMEN: FEVD en horizontes seleccionados\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for var in FIGURE1_VARIABLES:\n",
    "    print(f\"\\n{FIGURE1_LABELS[var]}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    var_data = fevd_df[fevd_df['variable'] == var]\n",
    "    \n",
    "    for h in [1, 4, 10, 40]:\n",
    "        h_data = var_data[var_data['horizon'] == h]\n",
    "        print(f\"  Horizon {h:2d}:  \", end=\"\")\n",
    "        for shock in SHOCK_ORDER:\n",
    "            share = h_data[h_data['shock'] == shock]['variance_share'].values\n",
    "            if len(share) > 0:\n",
    "                print(f\"{shock}={share[0]:5.1f}%  \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen IRFs - valores en impacto y pico\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN: IRFs a shocks de demanda\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for var in FIGURE2_VARIABLES:\n",
    "    print(f\"\\n{FIGURE2_LABELS[var]}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for shock in DEMAND_SHOCKS:\n",
    "        irf_data = figure2_irfs[\n",
    "            (figure2_irfs['variable'] == var) & \n",
    "            (figure2_irfs['shock'] == shock)\n",
    "        ].sort_values('period')\n",
    "        \n",
    "        if len(irf_data) > 0:\n",
    "            impact = irf_data[irf_data['period'] == 0]['value'].values[0]\n",
    "            peak_idx = irf_data['value'].abs().idxmax()\n",
    "            peak_period = irf_data.loc[peak_idx, 'period']\n",
    "            peak_value = irf_data.loc[peak_idx, 'value']\n",
    "            \n",
    "            print(f\"  {SHOCK_LABELS[shock]:15s}: Impact={impact:+.4f}, Peak={peak_value:+.4f} (t={int(peak_period)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REPLICACION COMPLETADA\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFiguras generadas:\")\n",
    "print(\"  - figure1_fevd.png: Forecast Error Variance Decomposition\")\n",
    "print(\"  - figure2_irfs.png: IRFs a shocks de demanda\")\n",
    "print(\"\\nDatos exportados:\")\n",
    "print(\"  - figure1_fevd_data.csv\")\n",
    "print(\"  - figure2_irfs_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar sesion Octave\n",
    "di.close()\n",
    "print(\"Sesion Octave cerrada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
